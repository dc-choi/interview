### 캐시란?
데이터의 원래 소스보다 더 빠르고 효율적으로 엑세스할 수 있는 임시 데이터 저장소

속도 향상을 위해서 캐시를 사용함.

캐시에 접근하는 것이 원본보다 더 쉽고 빨라야 한다.

동일한 데이터에 반복적으로 접근하는 경우가 많을 경우 캐시가 유용함

마찬가지로 데이터가 잘 변하지 않는 경우 캐시가 유용함

redis는 이에 맞춰서 캐시로서 사용하기 너무 좋은 솔루션이다.

우선 데이터를 단순하게 저장할 수 있다.

또한 인메모리 데이터 스토어이기 때문에 빠르게 읽기, 쓰기 작업을 진행할 수 있다.

### 읽기 전략
look-aside
```
읽기 전략중 제일 일반적으로 사용하는 방법

캐시에 데이터가 있다면 캐시에서 데이터를 가져오는 작업을 반복함.

캐시에서 데이터가 없다면 DB에서 데이터를 가져온 후 캐시에 다시 저장함.

찾는 데이터가 없는 경우에만 입력되기 때문에 lazy loading이라고 부르기도 함.

이 경우 redis가 다운되는 경우 DB에서 데이터를 가져올 수 있음.

대신 캐시에 커넥션이 많았다면 그 커넥션이 전부 DB로 붙음. 갑자기 많은 부하가 몰릴 수 있음.
```
캐시 워밍
```
캐시 미스가 많이 발생하는 경우 성능의 저하가 올 수 있기 때문에 미리 캐시에 데이터를 입력하는 작업이다.

상품 오픈 전 상품의 정보를 미리 DB에서 캐시에 올려두는 경우도 있다.
```

### 쓰기 전략
write-around
```
DB에만 데이터를 저장하는 방식. 캐시 미스가 발생한 경우에만 캐시에 DB 데이터를 입력한다.

캐시와 DB상 데이터가 다를 수 있다는 단점이 있다.
```

write-through
```
데이터를 저장하는 경우 캐시에도 함께 저장하는 방식.

저장할 때 마다 양쪽 모두에 저장해야 하기 때문에 상대적으로 느림.

저장하는 데이터가 재사용되지 않을 경우도 있는데 무조건 캐시에 넣어버려서 리소스 낭비가 발생할 수 있다.

따라서 리소스 낭비를 막기 위해서는 EX를 설정하는게 좋다. 하지만 이 부분에서 장애가 발생할 수 있다.
```

### 데이터 타입
string
```
제일 기본적인 데이터 타입, set 형태로 저장되는 데이터는 모두 string 형태로 저장된다.
```

bitmaps
```
string의 변형이라고 볼 수 있고 bit 연산이 가능함.
```

lists
```
데이터를 순서대로 저장함. 큐로 사용하기 적합함.
```

hashes
```
키안에 여러개의 키-값 형태의 데이터
```

sets
```
중복되지 않은 문자열의 집합
```

sorted sets
```
set과 비슷하지만 score라는 숫자 값으로 정렬됩니다.

데이터가 저장될 때 부터 score 순으로 정렬됨.

스코어가 같은 경우 사전 순으로 정렬되어 저장됨.
```

hyperloglogs
```
굉장히 많은 데이터를 다룰 때 주로 쓰며 중복되지 않는 값의 개수를 카운트할 때 사용합니다.

저장되는 용량이 매우 적지만 다시 확인할 수 없음.
```

stream
```
log를 저장하기 가장 좋은 자료구조.
```

### 사용 사례
카운팅
```
string의 단순 증감 연산을 사용하면 됨.

bits 연산을 사용하여 데이터 공간을 절약할 수 있지만 정수로 된 데이터만 가능.

hyperloglogs를 사용하여 대량의 데이터를 카운팅 할 때 훨씬 더 적절. 모든 string 데이터 값을 유니크하게 구분할 수 있음. 저장된 데이터가 몇백만, 몇천만 건이던 상관없이 모두 12kb임. 한번 저장한 데이터는 다시 불러올 수 없는데 데이터를 보호하기 위한 목적으로도 사용할 수 있음.
```

메시징
```
list를 메시지 큐로서 사용하기 적절함. 자체적으로 blocking 기능이 있어 적절히 사용하면 polling을 막을 수 있음. list에 키가 있을 경우에만 데이터를 추가할 수 있는 커맨드가 있음. sns의 경우 각 유저별로 타임라인에 보일 트윗을 캐싱하기 위해 해당 기능을 사용함. 자주 사용하는 유저에게 새로운 데이터를 캐싱할 수 있음. 자주 사용하지 않는 유저의 경우 기능이 동작하지 않음.

stream은 append-only라서 중간에 데이터가 바뀌지 않음. 키와 id를 저장할 수 있음. 일반적으로 *로 id를 저장할 수 있음. 이때 id는 시간값이다. 그 뒤에는 키-값을 매칭하여 데이터를 저장할 수 있다. 읽어오는 방법은 id값을 사용해 시간 대역대별로 저장된 값을 검색할 수도 있고 새로 들어오는 데이터만 리스닝 할 수 있다. 소비자라는 개념이 있어서 원하는 소비자만 특정 데이터를 읽게 할 수 도 있습니다. 메시징 브로커가 필요할 때 간단하게 사용할 수 있다.
```

세션 저장
```
로드 밸런싱 된 여러 서버간의 로그인한 유저의 세션을 저장, 블랙리스트 토큰 저장
```

실시간 랭킹 시스템
```
sorted set를 사용한 실시간 점수 및 랭킹 관리, 게임 점수 랭킹, 스트리밍 서비스 인기 순위
```

분산 락
```
Redlock 알고리즘을 통해 선착순 이벤트, 중복 결제 방지
```

실시간 채팅 및 알림
```
Pub/Sub을 사용해 채팅 메시지 및 이벤트 알림 처리, 라이브 스트리밍 채팅, 실시간 알림 서비스
```

Rate Limiting
```
특정 시간 내 요청 횟수를 제한하는 기능, 로그인 시도 제한, DDOS 방어
```

### 영구 저장
인메모리 데이터 스토어라 서버 재시작시 모든 데이터가 유실됨. 복제 기능을 사용해도 데이터 유실에 대해 안전하지 않음.

따라서 redis를 캐시 이외의 용도로 사용한다면 적절한 데이터 백업이 필요함.

AOF (append only file)
```
데이터를 변경하는 커맨드가 들어오면 커맨드를 그대로 모두 저장함. 데이터가 커지게 됨. 따라서 주기적으로 압축해서 재 작성되는 과정을 거쳐야 함.

레디스 프로토콜 형태로 저장됨.

자동으로 생성하는 방법은 redis.conf 파일에서 auto-aof-rewrite-pertenage 옵션을 세팅한다.

수동으로 생성하는 방법은 BGREWRITEAOF 커맨드를 사용해서 CLI 창에서 수동으로 AOF 파일 저장
```

RDB
```
스냅샷 방식을 사용하기 때문에 저장 당시의 메모리에 있는 데이터 그대로 파일로 저장함.

바이너리 파일 형태로 저장됨.

자동으로 생성하는 방법은 redis.conf 파일에서 save 옵션을 세팅한다.

수동으로 생성하는 방법은 BGSAVE 커맨드를 사용해서 CLI 창에서 수동으로 RDB 파일 저장.
```

이 둘을 선택하는 기준
```
백업은 필요하지만 어느정도 데이터 손실이 발생해도 괜찮은 경우
RDB 단독으로 사용.

장애 직전 상황까지 모든 데이터가 보장되어야 하는 경우
AOF 사용. 이때 APPENDFSYNC 옵션이 everysec인 경우 최대 1초 사이의 데이터 유실 가능성 존재

제일 강력한 내구성이 필요한 경우
둘 다 사용.
```

### 레디스 아키텍처
replication
```
마스터와 복제본을 따로 두는 방식

레디스의 복제가 되는 메커니즘은 비동기로 동작함.

마스터가 복제본에 데이터가 잘 전달되었는지 확인하지 않음.

HA 기능이 없어서 마스터에 장애가 발생하면 수동으로 변경해줘야 하는 작업들 많음.

복제본에 직접 접속해서 복제를 끊어야 하고 어플리케이션에서도 연결 설정을 변경해서 배포를 해줘야 함.
```

sentinel
```
위 방식에서 센티넬 노드만 있는 방식. 이 노드는 일반 노드들을 모니터링 하는 노드이다.

마스터가 죽는 경우 자동으로 페일오버를 발생시켜 기존의 복제본이 마스터가 되게 함.

이때 어플리케이션에서는 연결 설정을 변경하지 않아도 됨.

어플리케이션에서는 센티넬의 정보를 알고 있으면 센티넬이 변경된 마스터 정보로 매핑함.

센티넬은 항상 3대 이상의 홀수로 동작해야 하고 과반수 이상이 동의해야 페일 오버가 진행됨.
```

cluster
```
최소 3개의 마스터가 필요하며 샤딩 기능을 제공함.

모든 노드가 서로를 감시하다가 마스터가 비정상일 경우 자동으로 페일 오버를 진행함.

일반적으로 하나의 마스터에 하나의 복제본을 두는게 일반적이다.
```

### 장애 포인트 및 운영 꿀팁
레디스는 싱글 스레드로 동작함. => 한 사용자가 오래 걸리는 커멘드를 사용한다면 나머지 요청들은 처리할 수 없고 대기 하게 됩니다.
```
keys 명령어 대신에 scan 명령어 사용하기.

hash가 sorted set의 경우 키 내부에 데이터가 많아질 수록 성능이 저하됨.

그래서 하나의 키에 백만개 이상 저장하지 않도록 한다.

데이터가 많은 키의 값을 조회하는 경우 hgetall을 사용하지 않고 hscan을 사용할 것.

데이터가 많은 키를 삭제하는 경우 del을 사용하지 않고 unlink 커맨드를 사용할 것. (키를 백그라운드에서 삭제한다고 함.)
```

STOP-WRITES-ON-BGSAVE-ERROR
```
기본값은 yes, 이 옵션은 RDB 파일을 저장할 경우 장애가 발생하면 모든 쓰기 작업을 차단한다.

적절하게 모니터링을 하고 있다면 이 옵션은 끄는게 좋다.
```

MAXMEMORY-POLICY = ALLKEYS-LRU
```
레디스를 캐시로 사용하는 경우에는 expire-time을 설정하는 것이 좋음. 이 값을 설정하지 않으면 레디스 메모리가 가득참.

기본값은 메모리가 가득차면 입력을 하지 않는다는 이야기를 하기 때문에 장애가 발생할 수 있음.

위 값대로 설정하게 된다면 expire-time이 없는 데이터부터 삭제가 됨.
```

캐시 스탬피드
```
대규모 트래픽에서 TTL값을 너무 작게 설정한 경우 발생함.

look-aside 전략을 사용하는 경우 기존에 레디스에서 많은 조회가 일어나는 키의 캐시가 만료되면 DB로 많은 조회가 요청되면서 중복 읽기가 발생함. 해당 값을 DB에서 캐시로 넣는 중복 쓰기도 발생함.

TTL 시간을 넉넉하게 늘리는 것으로 해결함.
```

MaxMemory 값 설정
```
RDB 설정 & AOF rewrite시 fork()

Copy-on-Write로 인해 메모리를 두배로 사용하는 경우 발생 가능.

Persistence / 복제 사용 시 MaxMemory는 실제 메모리의 절반으로 설정.
```

Memory 관리
```
물리적으로 사용하고 있는 메모리를 모니터링 해야 함

used_memory가 아닌 used_memory_rss값을 모니터링 해야 함.

실제 저장된 데이터는 적은데 rss값은 큰 상황이 발생할 수 있음. 이 차이가 클 때 fragmention이 크다고 말함.

주로 삭제되는 키가 많을 때 fragmention이 증가함.

fragmention이 크게 증가한 경우 activefrag라는 옵션을 키면 도움이 됨.

이 옵션은 단편화가 많이 발생한 경우 키는 것을 권장함.
```

### redis와 memcached의 차이점
1. 키-값 + 다양한 자료구조 VS 단순 키-값
2. RDB, AOF를 통한 영구 저장 가능 VS 영속성 없음
3. redis cluster로 사딩 가능 VS 클라이언트에서 분산 처리
4. Pub/Sub, 트랜잭션, Lua 스크립트, 분산 락, 메시지 큐 VS 단순 캐시